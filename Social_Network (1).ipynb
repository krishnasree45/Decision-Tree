{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-PwtpyalUBl9"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pandas as pd\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "df = pd.read_csv('/content/Social_Network_Ads.csv')\n",
        "\n",
        "# Add feature columns for input and output\n",
        "feature_cols = ['Gender','Age','EstimatedSalary'] # Social Network Dataset\n",
        "\n",
        "# Encode the categorical features\n",
        "df['Gender'].replace(to_replace=['Male', 'Female'], value=[1,2], inplace=True) # Social Network Dataset\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df['Purchased']\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decission Tree Classification**"
      ],
      "metadata": {
        "id": "vIBjavACeRPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "'''\n",
        "Authors: Ashwani Kashyap, Anshul Pardhi\n",
        "'''\n",
        "\n",
        "import math\n",
        "\n",
        "def unique_vals(rows, col):\n",
        "    \"\"\"Find the unique values for a column in a dataset.\"\"\"\n",
        "    return set([row[col] for row in rows])\n",
        "\n",
        "def class_counts(rows):\n",
        "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
        "    counts = {}  # a dictionary of label -> count.\n",
        "    for row in rows:\n",
        "        # in our dataset format, the label is always the last column\n",
        "        label = row[-1]\n",
        "        if label not in counts:\n",
        "            counts[label] = 0\n",
        "        counts[label] += 1\n",
        "    return counts\n",
        "\n",
        "\n",
        "def max_label(dict):\n",
        "    max_count = 0\n",
        "    label = \"\"\n",
        "\n",
        "    for key, value in dict.items():\n",
        "        if dict[key] > max_count:\n",
        "            max_count = dict[key]\n",
        "            label = key\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def is_numeric(value):\n",
        "    \"\"\"Test if a value is numeric.\"\"\"\n",
        "    return isinstance(value, int) or isinstance(value, float)\n",
        "\n",
        "\n",
        "\n",
        "class Question:\n",
        "    \"\"\"A Question is used to partition a dataset.\n",
        "\n",
        "    This class just records a 'column number' (e.g., 0 for Color) and a\n",
        "    'column value' (e.g., Green). The 'match' method is used to compare\n",
        "    the feature value in an example to the feature value stored in the\n",
        "    question. See the demo below.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, column, value, header):\n",
        "        self.column = column\n",
        "        self.value = value\n",
        "        self.header = header\n",
        "\n",
        "    def match(self, example):\n",
        "        # Compare the feature value in an example to the\n",
        "        # feature value in this question.\n",
        "        val = example[self.column]\n",
        "        if is_numeric(val):\n",
        "            return val >= self.value\n",
        "        else:\n",
        "            return val == self.value\n",
        "\n",
        "    def __repr__(self):\n",
        "        # This is just a helper method to print\n",
        "        # the question in a readable format.\n",
        "        condition = \"==\"\n",
        "        if is_numeric(self.value):\n",
        "            condition = \">=\"\n",
        "        return \"Is %s %s %s?\" % (\n",
        "            self.header[self.column], condition, str(self.value))\n",
        "\n",
        "\n",
        "def partition(rows, question):\n",
        "    \"\"\"Partitions a dataset.\n",
        "\n",
        "    For each row in the dataset, check if it matches the question. If\n",
        "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
        "    \"\"\"\n",
        "    true_rows, false_rows = [], []\n",
        "    for row in rows:\n",
        "        if question.match(row):\n",
        "            true_rows.append(row)\n",
        "        else:\n",
        "            false_rows.append(row)\n",
        "    return true_rows, false_rows\n",
        "\n",
        "\n",
        "def gini(rows):\n",
        "    \"\"\"Calculate the Gini Impurity for a list of rows.\n",
        "\n",
        "    There are a few different ways to do this, I thought this one was\n",
        "    the most concise. See:\n",
        "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
        "    \"\"\"\n",
        "    counts = class_counts(rows)\n",
        "    impurity = 1\n",
        "    for lbl in counts:\n",
        "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
        "        impurity -= prob_of_lbl**2\n",
        "    return impurity\n",
        "\n",
        "def entropy(rows):\n",
        "\n",
        "    # compute the entropy.\n",
        "    entries = class_counts(rows)\n",
        "    avg_entropy = 0\n",
        "    size = float(len(rows))\n",
        "    for label in entries:\n",
        "        prob = entries[label] / size\n",
        "        avg_entropy = avg_entropy + (prob * math.log(prob, 2))\n",
        "    return -1*avg_entropy\n",
        "\n",
        "\n",
        "def info_gain(left, right, current_uncertainty):\n",
        "    \"\"\"Information Gain.\n",
        "\n",
        "    The uncertainty of the starting node, minus the weighted impurity of\n",
        "    two child nodes.\n",
        "    \"\"\"\n",
        "    p = float(len(left)) / (len(left) + len(right))\n",
        "\n",
        "    ## TODO: Step 3, Use Entropy in place of Gini\n",
        "    return current_uncertainty - p * entropy(left) - (1 - p) * entropy(right)\n",
        "\n",
        "def split_ratio(left, right):\n",
        "    d1 = float(len(left)) / (len(left) + len(right))\n",
        "    d2 = 1 - d1\n",
        "    if d1== 0 or d2 ==0:\n",
        "        return -1\n",
        "    return -1*(d1*math.log(d1,2)+ d2*math.log(d2,2))\n",
        "\n",
        "def gain_ratio(info_gain, split_ratio):\n",
        "    return float(info_gain/split_ratio)\n",
        "\n",
        "def find_best_split(rows, header, metric):\n",
        "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
        "    and calculating the information gain.\"\"\"\n",
        "    best_gain = 0  # keep track of the best information gain\n",
        "    best_question = None  # keep train of the feature / value that produced it\n",
        "    current_uncertainty = entropy(rows)\n",
        "    n_features = len(rows[0]) - 1  # number of columns\n",
        "    rows_len = len(rows)\n",
        "    gini_total_dataset = gini(rows)\n",
        "\n",
        "    for col in range(n_features):  # for each feature\n",
        "\n",
        "        values = set([row[col] for row in rows])  # unique values in the column\n",
        "\n",
        "        for val in values:  # for each value\n",
        "\n",
        "            question = Question(col, val, header)\n",
        "\n",
        "            # try splitting the dataset\n",
        "            left, right = partition(rows, question)\n",
        "            if metric == \"gini\":   \n",
        "                gini_left = gini(left)\n",
        "                gini_right = gini(right)\n",
        "                gini_of_feature = ((len(left)/ rows_len) * gini_left) + ((len(right)/rows_len) * gini_right)\n",
        "                gini_delta = gini_total_dataset - gini_of_feature\n",
        "                if(gini_delta >= best_gain):\n",
        "                    best_gain, best_question = gini_delta, question\n",
        "            elif metric == \"info_gain\":\n",
        "                gain = info_gain(left, right, current_uncertainty)\n",
        "                if gain >= best_gain:\n",
        "                    best_gain, best_question = gain, question\n",
        "            else: # Gain Ratio\n",
        "                gain_ratio_cal = gain_ratio(info_gain(left, right, current_uncertainty), split_ratio(left, right))\n",
        "                if gain_ratio_cal >= best_gain:\n",
        "                    best_gain, best_question = gain_ratio_cal, question\n",
        "\n",
        "            # Skip this split if it doesn't divide the\n",
        "            # dataset.\n",
        "            if len(left) == 0 or len(right) == 0:\n",
        "                continue\n",
        "\n",
        "    return best_gain, best_question\n",
        "\n",
        "## TODO: Step 2\n",
        "class Leaf:\n",
        "    \"\"\"A Leaf node classifies data.\n",
        "\n",
        "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
        "    it appears in the rows from the training data that reach this leaf.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rows, id, depth):\n",
        "        self.predictions = class_counts(rows)\n",
        "        self.predicted_label = max_label(self.predictions)\n",
        "        self.id = id\n",
        "        self.depth = depth\n",
        "\n",
        "## TODO: Step 1\n",
        "class Decision_Node:\n",
        "    \"\"\"A Decision Node asks a question.\n",
        "\n",
        "    This holds a reference to the question, and to the two child nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 question,\n",
        "                 true_branch,\n",
        "                 false_branch,\n",
        "                 depth,\n",
        "                 id,\n",
        "                 rows):\n",
        "        self.question = question\n",
        "        self.true_branch = true_branch\n",
        "        self.false_branch = false_branch\n",
        "        self.depth = depth\n",
        "        self.id = id\n",
        "        self.rows = rows\n",
        "\n",
        "\n",
        "## TODO: Step 3\n",
        "def build_tree(rows, header, depth=0, id=0):\n",
        "    \"\"\"Builds the tree.\n",
        "\n",
        "    Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
        "    for the base case (no further information gain). 3) Prepare for\n",
        "    giant stack traces.\n",
        "    \"\"\"\n",
        "\n",
        "    gain, question = find_best_split(rows, header, \"gain_ratio\")\n",
        "\n",
        "    if gain == 0:\n",
        "        return Leaf(rows, id, depth)\n",
        "\n",
        "    true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "    # Recursively build the true branch.\n",
        "    true_branch = build_tree(true_rows, header, depth + 1, 2 * id + 2)\n",
        "\n",
        "    # Recursively build the false branch.\n",
        "    false_branch = build_tree(false_rows, header, depth + 1, 2 * id + 1)\n",
        "\n",
        "    return Decision_Node(question, true_branch, false_branch, depth, id, rows)\n",
        "\n",
        "## TODO: Step 8 - already done for you\n",
        "def prune_tree(node, prunedList):\n",
        "    \"\"\"Builds the tree.\n",
        "\n",
        "    Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
        "    for the base case (no further information gain). 3) Prepare for\n",
        "    giant stack traces.\n",
        "    \"\"\"\n",
        "\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf):\n",
        "        return node\n",
        "    # If we reach a pruned node, make that node a leaf node and return. Since it becomes a leaf node, the nodes\n",
        "    # below it are automatically not considered\n",
        "    if int(node.id) in prunedList:\n",
        "        return Leaf(node.rows, node.id, node.depth)\n",
        "\n",
        "    # Call this function recursively on the true branch\n",
        "    node.true_branch = prune_tree(node.true_branch, prunedList)\n",
        "\n",
        "    # Call this function recursively on the false branch\n",
        "    node.false_branch = prune_tree(node.false_branch, prunedList)\n",
        "\n",
        "    return node\n",
        "\n",
        "## TODO: Step 6\n",
        "def classify(row, node):\n",
        "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
        "\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf):\n",
        "        return node.predicted_label\n",
        "\n",
        "    if node.question.match(row):\n",
        "        return classify(row, node.true_branch)\n",
        "    else:\n",
        "        return classify(row, node.false_branch)\n",
        "\n",
        "## TODO: Step 4\n",
        "def print_tree(node, spacing=\"\"):\n",
        "    \"\"\"World's most elegant tree printing function.\"\"\"\n",
        "\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf):\n",
        "        print(spacing + \"Leaf id: \" + str(node.id) + \" Predictions: \" + str(node.predictions) + \" Label Class: \" + str(node.predicted_label))\n",
        "        return\n",
        "\n",
        "    # Print the question at this node\n",
        "    print(spacing + str(node.question) + \" id: \" + str(node.id) + \" depth: \" + str(node.depth))\n",
        "\n",
        "    # Call this function recursively on the true branch\n",
        "    print(spacing + '--> True:')\n",
        "    print_tree(node.true_branch, spacing + \"  \")\n",
        "\n",
        "    # Call this function recursively on the false branch\n",
        "    print(spacing + '--> False:')\n",
        "    print_tree(node.false_branch, spacing + \"  \")\n",
        "\n",
        "\n",
        "def print_leaf(counts):\n",
        "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
        "    total = sum(counts.values()) * 1.0\n",
        "    probs = {}\n",
        "    for lbl in counts.keys():\n",
        "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
        "    return probs\n",
        "\n",
        "def getLeafNodes(node, leafNodes =[]):\n",
        "\n",
        "    # Base case\n",
        "    if isinstance(node, Leaf):\n",
        "        leafNodes.append(node)\n",
        "        return\n",
        "\n",
        "    # Recursive right call for true values\n",
        "    getLeafNodes(node.true_branch, leafNodes)\n",
        "\n",
        "    # Recursive left call for false values\n",
        "    getLeafNodes(node.false_branch, leafNodes)\n",
        "\n",
        "    return leafNodes\n",
        "\n",
        "\n",
        "def getInnerNodes(node, innerNodes =[]):\n",
        "\n",
        "    # Base case\n",
        "    if isinstance(node, Leaf):\n",
        "        return\n",
        "\n",
        "    innerNodes.append(node)\n",
        "\n",
        "    # Recursive right call for true values\n",
        "    getInnerNodes(node.true_branch, innerNodes)\n",
        "\n",
        "    # Recursive left call for false values\n",
        "    getInnerNodes(node.false_branch, innerNodes)\n",
        "\n",
        "    return innerNodes\n",
        "\n",
        "## TODO: Step 6\n",
        "def computeAccuracy(rows, node):\n",
        "\n",
        "    count = len(rows)\n",
        "    if count == 0:\n",
        "        return 0\n",
        "\n",
        "    accuracy = 0\n",
        "    for row in rows:\n",
        "        # last entry of the column is the actual label\n",
        "        if row[-1] == classify(row, node):\n",
        "            accuracy += 1\n",
        "    return round(accuracy/count, 2)\n",
        "\n",
        "\n",
        "# default data set\n",
        "df = pd.read_csv('/content/Social_Network_Ads copy.csv')\n",
        "# df = pd.read_csv('data_set/contraceptive-method-choice.csv')\n",
        "# df = pd.read_csv('data_set/xor-gate-3-inputs.csv')\n",
        "header = list(df.columns)\n",
        "\n",
        "lst = df.values.tolist()\n",
        "\n",
        "trainDF, testDF = model_selection.train_test_split(lst, test_size=0.2)\n",
        "t = build_tree(trainDF, header)\n",
        "\n",
        "\n",
        "# get leaf and inner nodes\n",
        "print(\"\\nLeaf nodes ****************\")\n",
        "leaves = getLeafNodes(t)\n",
        "for leaf in leaves:\n",
        "    print(\"id = \" + str(leaf.id) + \" depth =\" + str(leaf.depth))\n",
        "\n",
        "print(\"\\nNon-leaf nodes ****************\")\n",
        "innerNodes = getInnerNodes(t)\n",
        "\n",
        "for inner in innerNodes:\n",
        "    print(\"id = \" + str(inner.id) + \" depth =\" + str(inner.depth))\n",
        "\n",
        "# print tree\n",
        "maxAccuracy = computeAccuracy(testDF, t)\n",
        "print(\"\\nTree before pruning with accuracy: \" + str(maxAccuracy*100) + \"\\n\")\n",
        "print_tree(t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2dg0fZLeQsJ",
        "outputId": "0a54e00e-5227-4061-b116-ead558ce19f5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Leaf nodes ****************\n",
            "id = 254 depth =7\n",
            "id = 1018 depth =9\n",
            "id = 2036 depth =10\n",
            "id = 4072 depth =11\n",
            "id = 8144 depth =12\n",
            "id = 16288 depth =13\n",
            "id = 32576 depth =14\n",
            "id = 32575 depth =14\n",
            "id = 1016 depth =9\n",
            "id = 1015 depth =9\n",
            "id = 252 depth =7\n",
            "id = 251 depth =7\n",
            "id = 124 depth =6\n",
            "id = 123 depth =6\n",
            "id = 29 depth =4\n",
            "id = 13 depth =3\n",
            "id = 12 depth =3\n",
            "id = 24 depth =4\n",
            "id = 23 depth =4\n",
            "id = 46 depth =5\n",
            "id = 45 depth =5\n",
            "id = 21 depth =4\n",
            "id = 9 depth =3\n",
            "id = 18 depth =4\n",
            "id = 302 depth =8\n",
            "id = 301 depth =8\n",
            "id = 149 depth =7\n",
            "id = 73 depth =6\n",
            "id = 35 depth =5\n",
            "id = 142 depth =7\n",
            "id = 141 depth =7\n",
            "id = 69 depth =6\n",
            "id = 33 depth =5\n",
            "id = 270 depth =8\n",
            "id = 1082 depth =10\n",
            "id = 1081 depth =10\n",
            "id = 539 depth =9\n",
            "id = 133 depth =7\n",
            "id = 65 depth =6\n",
            "id = 64 depth =6\n",
            "id = 258 depth =8\n",
            "id = 257 depth =8\n",
            "id = 127 depth =7\n",
            "\n",
            "Non-leaf nodes ****************\n",
            "id = 0 depth =0\n",
            "id = 2 depth =1\n",
            "id = 6 depth =2\n",
            "id = 14 depth =3\n",
            "id = 30 depth =4\n",
            "id = 62 depth =5\n",
            "id = 126 depth =6\n",
            "id = 253 depth =7\n",
            "id = 508 depth =8\n",
            "id = 1017 depth =9\n",
            "id = 2035 depth =10\n",
            "id = 4071 depth =11\n",
            "id = 8143 depth =12\n",
            "id = 16287 depth =13\n",
            "id = 507 depth =8\n",
            "id = 125 depth =6\n",
            "id = 61 depth =5\n",
            "id = 5 depth =2\n",
            "id = 11 depth =3\n",
            "id = 1 depth =1\n",
            "id = 4 depth =2\n",
            "id = 10 depth =3\n",
            "id = 22 depth =4\n",
            "id = 3 depth =2\n",
            "id = 8 depth =3\n",
            "id = 17 depth =4\n",
            "id = 36 depth =5\n",
            "id = 74 depth =6\n",
            "id = 150 depth =7\n",
            "id = 7 depth =3\n",
            "id = 16 depth =4\n",
            "id = 34 depth =5\n",
            "id = 70 depth =6\n",
            "id = 15 depth =4\n",
            "id = 32 depth =5\n",
            "id = 66 depth =6\n",
            "id = 134 depth =7\n",
            "id = 269 depth =8\n",
            "id = 540 depth =9\n",
            "id = 31 depth =5\n",
            "id = 63 depth =6\n",
            "id = 128 depth =7\n",
            "\n",
            "Tree before pruning with accuracy: 89.0\n",
            "\n",
            "Is Age >= 45? id: 0 depth: 0\n",
            "--> True:\n",
            "  Is EstimatedSalary >= 42000? id: 2 depth: 1\n",
            "  --> True:\n",
            "    Is User ID >= 15596984? id: 6 depth: 2\n",
            "    --> True:\n",
            "      Is User ID >= 15600379? id: 14 depth: 3\n",
            "      --> True:\n",
            "        Is User ID >= 15609669? id: 30 depth: 4\n",
            "        --> True:\n",
            "          Is EstimatedSalary >= 45000? id: 62 depth: 5\n",
            "          --> True:\n",
            "            Is Age >= 53? id: 126 depth: 6\n",
            "            --> True:\n",
            "              Leaf id: 254 Predictions: {1: 16} Label Class: 1\n",
            "            --> False:\n",
            "              Is User ID >= 15639576? id: 253 depth: 7\n",
            "              --> True:\n",
            "                Is EstimatedSalary >= 117000? id: 508 depth: 8\n",
            "                --> True:\n",
            "                  Leaf id: 1018 Predictions: {1: 9} Label Class: 1\n",
            "                --> False:\n",
            "                  Is User ID >= 15791174? id: 1017 depth: 9\n",
            "                  --> True:\n",
            "                    Leaf id: 2036 Predictions: {0: 2} Label Class: 0\n",
            "                  --> False:\n",
            "                    Is Age >= 47? id: 2035 depth: 10\n",
            "                    --> True:\n",
            "                      Leaf id: 4072 Predictions: {1: 5} Label Class: 1\n",
            "                    --> False:\n",
            "                      Is EstimatedSalary >= 96000? id: 4071 depth: 11\n",
            "                      --> True:\n",
            "                        Leaf id: 8144 Predictions: {0: 1} Label Class: 0\n",
            "                      --> False:\n",
            "                        Is Age >= 46? id: 8143 depth: 12\n",
            "                        --> True:\n",
            "                          Leaf id: 16288 Predictions: {1: 2} Label Class: 1\n",
            "                        --> False:\n",
            "                          Is EstimatedSalary >= 79000? id: 16287 depth: 13\n",
            "                          --> True:\n",
            "                            Leaf id: 32576 Predictions: {0: 1} Label Class: 0\n",
            "                          --> False:\n",
            "                            Leaf id: 32575 Predictions: {1: 1} Label Class: 1\n",
            "              --> False:\n",
            "                Is User ID >= 15636023? id: 507 depth: 8\n",
            "                --> True:\n",
            "                  Leaf id: 1016 Predictions: {0: 2} Label Class: 0\n",
            "                --> False:\n",
            "                  Leaf id: 1015 Predictions: {1: 1} Label Class: 1\n",
            "          --> False:\n",
            "            Is Age >= 60? id: 125 depth: 6\n",
            "            --> True:\n",
            "              Leaf id: 252 Predictions: {1: 2} Label Class: 1\n",
            "            --> False:\n",
            "              Leaf id: 251 Predictions: {0: 2} Label Class: 0\n",
            "        --> False:\n",
            "          Is Age >= 51? id: 61 depth: 5\n",
            "          --> True:\n",
            "            Leaf id: 124 Predictions: {0: 2} Label Class: 0\n",
            "          --> False:\n",
            "            Leaf id: 123 Predictions: {1: 1} Label Class: 1\n",
            "      --> False:\n",
            "        Leaf id: 29 Predictions: {0: 1} Label Class: 0\n",
            "    --> False:\n",
            "      Leaf id: 13 Predictions: {1: 5} Label Class: 1\n",
            "  --> False:\n",
            "    Is EstimatedSalary >= 23000? id: 5 depth: 2\n",
            "    --> True:\n",
            "      Leaf id: 12 Predictions: {1: 26} Label Class: 1\n",
            "    --> False:\n",
            "      Is User ID >= 15697424? id: 11 depth: 3\n",
            "      --> True:\n",
            "        Leaf id: 24 Predictions: {0: 1} Label Class: 0\n",
            "      --> False:\n",
            "        Leaf id: 23 Predictions: {1: 4} Label Class: 1\n",
            "--> False:\n",
            "  Is EstimatedSalary >= 118000? id: 1 depth: 1\n",
            "  --> True:\n",
            "    Is Age >= 43? id: 4 depth: 2\n",
            "    --> True:\n",
            "      Is EstimatedSalary >= 133000? id: 10 depth: 3\n",
            "      --> True:\n",
            "        Is EstimatedSalary >= 139000? id: 22 depth: 4\n",
            "        --> True:\n",
            "          Leaf id: 46 Predictions: {1: 1} Label Class: 1\n",
            "        --> False:\n",
            "          Leaf id: 45 Predictions: {0: 1} Label Class: 0\n",
            "      --> False:\n",
            "        Leaf id: 21 Predictions: {1: 1} Label Class: 1\n",
            "    --> False:\n",
            "      Leaf id: 9 Predictions: {1: 18} Label Class: 1\n",
            "  --> False:\n",
            "    Is EstimatedSalary >= 90000? id: 3 depth: 2\n",
            "    --> True:\n",
            "      Is Age >= 39? id: 8 depth: 3\n",
            "      --> True:\n",
            "        Leaf id: 18 Predictions: {1: 6} Label Class: 1\n",
            "      --> False:\n",
            "        Is User ID >= 15651983? id: 17 depth: 4\n",
            "        --> True:\n",
            "          Is EstimatedSalary >= 93000? id: 36 depth: 5\n",
            "          --> True:\n",
            "            Is User ID >= 15772798? id: 74 depth: 6\n",
            "            --> True:\n",
            "              Is Age >= 38? id: 150 depth: 7\n",
            "              --> True:\n",
            "                Leaf id: 302 Predictions: {1: 1} Label Class: 1\n",
            "              --> False:\n",
            "                Leaf id: 301 Predictions: {0: 3} Label Class: 0\n",
            "            --> False:\n",
            "              Leaf id: 149 Predictions: {1: 5} Label Class: 1\n",
            "          --> False:\n",
            "            Leaf id: 73 Predictions: {0: 1} Label Class: 0\n",
            "        --> False:\n",
            "          Leaf id: 35 Predictions: {0: 3} Label Class: 0\n",
            "    --> False:\n",
            "      Is Age >= 42? id: 7 depth: 3\n",
            "      --> True:\n",
            "        Is User ID >= 15683758? id: 16 depth: 4\n",
            "        --> True:\n",
            "          Is EstimatedSalary >= 80000? id: 34 depth: 5\n",
            "          --> True:\n",
            "            Is Gender == Male? id: 70 depth: 6\n",
            "            --> True:\n",
            "              Leaf id: 142 Predictions: {0: 1} Label Class: 0\n",
            "            --> False:\n",
            "              Leaf id: 141 Predictions: {1: 1} Label Class: 1\n",
            "          --> False:\n",
            "            Leaf id: 69 Predictions: {0: 5} Label Class: 0\n",
            "        --> False:\n",
            "          Leaf id: 33 Predictions: {1: 1} Label Class: 1\n",
            "      --> False:\n",
            "        Is User ID >= 15578006? id: 15 depth: 4\n",
            "        --> True:\n",
            "          Is EstimatedSalary >= 75000? id: 32 depth: 5\n",
            "          --> True:\n",
            "            Is Age >= 37? id: 66 depth: 6\n",
            "            --> True:\n",
            "              Is User ID >= 15721592? id: 134 depth: 7\n",
            "              --> True:\n",
            "                Leaf id: 270 Predictions: {0: 6} Label Class: 0\n",
            "              --> False:\n",
            "                Is Age >= 39? id: 269 depth: 8\n",
            "                --> True:\n",
            "                  Is EstimatedSalary >= 77000? id: 540 depth: 9\n",
            "                  --> True:\n",
            "                    Leaf id: 1082 Predictions: {0: 3} Label Class: 0\n",
            "                  --> False:\n",
            "                    Leaf id: 1081 Predictions: {1: 1} Label Class: 1\n",
            "                --> False:\n",
            "                  Leaf id: 539 Predictions: {1: 2} Label Class: 1\n",
            "            --> False:\n",
            "              Leaf id: 133 Predictions: {0: 38} Label Class: 0\n",
            "          --> False:\n",
            "            Leaf id: 65 Predictions: {0: 128} Label Class: 0\n",
            "        --> False:\n",
            "          Is EstimatedSalary >= 87000? id: 31 depth: 5\n",
            "          --> True:\n",
            "            Leaf id: 64 Predictions: {1: 1} Label Class: 1\n",
            "          --> False:\n",
            "            Is Age >= 40? id: 63 depth: 6\n",
            "            --> True:\n",
            "              Is EstimatedSalary >= 71000? id: 128 depth: 7\n",
            "              --> True:\n",
            "                Leaf id: 258 Predictions: {1: 1} Label Class: 1\n",
            "              --> False:\n",
            "                Leaf id: 257 Predictions: {0: 1} Label Class: 0\n",
            "            --> False:\n",
            "              Leaf id: 127 Predictions: {0: 7} Label Class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM Classification**"
      ],
      "metadata": {
        "id": "XF5s1R7YdDxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC()\n",
        "# instantiate classifier with default hyperparameters\n",
        "clf = svm.SVC(decision_function_shape='ovo')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred= clf.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqVE6iqJdAP0",
        "outputId": "b55ad2cd-44e6-42d8-9a5b-325fb652bc52"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy score with default hyperparameters: 0.8250\n",
            "0.825\n",
            "[[56  2]\n",
            " [12 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89        58\n",
            "           1       0.83      0.45      0.59        22\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.83      0.71      0.74        80\n",
            "weighted avg       0.83      0.82      0.81        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Learning Classification**"
      ],
      "metadata": {
        "id": "ertU5C_id3vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder =  LabelEncoder()\n",
        "y1 = encoder.fit_transform(y)\n",
        "Y = pd.get_dummies(y1).values\n",
        "print(Y[0:5])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "  ])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=50, epochs=100)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred=np.argmax(y_pred, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "#print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv_XHuw-Yy2s",
        "outputId": "11e8e99c-7eee-49b0-ed36-0cbae03aaab9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]]\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 14246.2812 - accuracy: 0.3781\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 11531.0400 - accuracy: 0.3781\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 9729.1973 - accuracy: 0.3781\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 8095.8179 - accuracy: 0.3781\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 6540.4097 - accuracy: 0.3781\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 5072.0586 - accuracy: 0.3781\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3613.5879 - accuracy: 0.3781\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2228.9385 - accuracy: 0.3781\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 813.2925 - accuracy: 0.3781\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 101.3475 - accuracy: 0.4844\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 94.8172 - accuracy: 0.5156\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 106.4691 - accuracy: 0.4531\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 97.7588 - accuracy: 0.4969\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 94.5040 - accuracy: 0.4781\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 121.8558 - accuracy: 0.5094\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 98.8613 - accuracy: 0.4844\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 88.7685 - accuracy: 0.5063\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 121.8977 - accuracy: 0.4406\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 89.6761 - accuracy: 0.5031\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 94.9401 - accuracy: 0.4656\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 98.7725 - accuracy: 0.5156\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 86.3877 - accuracy: 0.5031\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 86.5800 - accuracy: 0.5281\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 109.2086 - accuracy: 0.4719\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 95.4207 - accuracy: 0.5031\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 99.0725 - accuracy: 0.4906\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 102.4093 - accuracy: 0.4656\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 124.3017 - accuracy: 0.4906\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 89.9325 - accuracy: 0.5156\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 88.0986 - accuracy: 0.5156\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 109.4984 - accuracy: 0.4719\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 83.9556 - accuracy: 0.5469\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 104.5450 - accuracy: 0.4719\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 102.9922 - accuracy: 0.4781\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 87.6865 - accuracy: 0.5469\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 98.1655 - accuracy: 0.5031\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 93.8234 - accuracy: 0.5219\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 115.4386 - accuracy: 0.4719\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 69.8389 - accuracy: 0.4938\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 116.9276 - accuracy: 0.5219\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 102.2847 - accuracy: 0.4844\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 92.4890 - accuracy: 0.4656\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 77.9588 - accuracy: 0.5625\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 99.3578 - accuracy: 0.4969\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 100.7632 - accuracy: 0.4844\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 85.4290 - accuracy: 0.5156\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 105.2233 - accuracy: 0.4719\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 109.4633 - accuracy: 0.4781\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 88.3583 - accuracy: 0.5281\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 97.1773 - accuracy: 0.4719\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 90.9414 - accuracy: 0.5219\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 81.9979 - accuracy: 0.4750\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 124.3906 - accuracy: 0.4469\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 85.9172 - accuracy: 0.5219\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 103.2832 - accuracy: 0.4719\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 85.2103 - accuracy: 0.5469\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 82.5454 - accuracy: 0.5531\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 92.4313 - accuracy: 0.5219\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 119.8910 - accuracy: 0.5281\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 117.9046 - accuracy: 0.4656\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 82.6403 - accuracy: 0.5219\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 87.5174 - accuracy: 0.4969\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 114.1260 - accuracy: 0.4719\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 97.3907 - accuracy: 0.4906\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 84.1111 - accuracy: 0.5281\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 104.1908 - accuracy: 0.4969\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 87.9820 - accuracy: 0.5094\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 88.2639 - accuracy: 0.5156\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 92.9318 - accuracy: 0.4844\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 87.7653 - accuracy: 0.5406\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 105.8766 - accuracy: 0.4969\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 103.3997 - accuracy: 0.4719\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 93.9225 - accuracy: 0.4719\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 99.8120 - accuracy: 0.5531\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 102.9120 - accuracy: 0.5219\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 72.2018 - accuracy: 0.5250\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 115.6193 - accuracy: 0.4656\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 91.3606 - accuracy: 0.5156\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 110.6086 - accuracy: 0.4469\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 100.9512 - accuracy: 0.4406\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 81.7196 - accuracy: 0.5344\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 90.1482 - accuracy: 0.4969\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 123.0521 - accuracy: 0.4656\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 106.3804 - accuracy: 0.4656\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 86.0929 - accuracy: 0.5094\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 94.7858 - accuracy: 0.5219\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 72.1249 - accuracy: 0.5281\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 93.4770 - accuracy: 0.4594\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 105.2484 - accuracy: 0.4969\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 77.3983 - accuracy: 0.5531\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 90.7225 - accuracy: 0.4969\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 93.7665 - accuracy: 0.5219\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 86.2601 - accuracy: 0.5031\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 81.7339 - accuracy: 0.5531\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 86.8413 - accuracy: 0.5250\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 108.8856 - accuracy: 0.4969\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 90.3411 - accuracy: 0.5437\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 101.7089 - accuracy: 0.4906\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 73.4016 - accuracy: 0.5469\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 83.6253 - accuracy: 0.5094\n",
            "Test loss: 135.35015869140625\n",
            "Test accuracy: 0.2750000059604645\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "[[ 0 58]\n",
            " [ 0 22]]\n",
            "[[ 0 58]\n",
            " [ 0 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        58\n",
            "           1       0.28      1.00      0.43        22\n",
            "\n",
            "    accuracy                           0.28        80\n",
            "   macro avg       0.14      0.50      0.22        80\n",
            "weighted avg       0.08      0.28      0.12        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3r-YsCWaYbJq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}